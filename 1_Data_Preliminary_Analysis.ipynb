{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae35934",
   "metadata": {},
   "source": [
    "# 1.0 Data & Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2235944",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains the data and preliminary analysis of a deep learning for image classification project. The notebook imports necessary libraries such as Tensorflow, Pandas, Matplotlib, and Seaborn and maps the ImageNet class index to human-readable labels. It analyses and visualises class imbalances in training and validation datasets using class counts and percentages. It also analyses the distribution of image file sizes within each class in the training dataset. The notebook provides clear and concise code with comments explaining each step of the analysis. The visualisations are presented in an explicit and effective manner using Seaborn and Matplotlib libraries. \n",
    "\n",
    "The notebook is structured into three  main sections:\n",
    "1. **Importing Required Libraries:** This section imports necessary libraries such as Tensorflow, Pandas, Matplotlib, and Seaborn.\n",
    "2. **Mapping ImageNet Class Index to Human-Readable Labels:** This section maps the ImageNet class index to human-readable labels using a JSON file obtained from the internet.\n",
    "3. **Class Distribution Analysis:** This section analyses and visualises class imbalances in the training and validation datasets using class counts and percentages. It also analyses the distribution of image file sizes within each class in the training dataset.\n",
    "\n",
    "Moreover, this notebook will serve as a starting point for further investigation and modelling for this project by providing essential insights into the class distribution and size of images that will be utilised for training the deep learning for the image classification model. Furthermore, the insights generated will help to guide future decision-making in the development and deployment of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5e927",
   "metadata": {},
   "source": [
    "## 1.1 Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aac3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from packaging import version\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8dc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the TensorFlow version is 2.10.0; if not, raise an AssertionError with a message indicating \n",
    "# the required version\n",
    "assert version.parse(tf.__version__) == version.parse('2.10.0'), \"Please install TF version 2.10.0. Current version: \" + str(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9f8875",
   "metadata": {},
   "source": [
    "## 1.2 Mapping Imagenet Class Index to Human-Readable Labels\n",
    "\n",
    "> The ImageNet metadata JSON file was obtained from: https://www.kaggle.com/keras/resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e811a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "imagenet2idx = {}\n",
    "\n",
    "# Open the file 'imagenet_class_index.json' in read mode and assign its content to the dictionary\n",
    "with open('imagenet_class_index.json') as f:\n",
    "    idx2imagenet = json.load(f)\n",
    "    \n",
    "# Print the contents\n",
    "idx2imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dictionary with keys and values from 'idx2imagenet'\n",
    "# The keys are the first elements of the values in 'idx2imagenet' and the values are a list of the \n",
    "# corresponding key in 'idx2imagenet' and the second element of the values in 'idx2imagenet'\n",
    "imagenet2idx = {v[0]: [k, v[1]] for k, v in idx2imagenet.items()}\n",
    "\n",
    "# Print the contents\n",
    "imagenet2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d1056",
   "metadata": {},
   "source": [
    "## 1.3 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a5777",
   "metadata": {},
   "source": [
    "### 1.3.1 Class Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for training and validation datasets\n",
    "TRAIN_PATH = \"imageset/train\"\n",
    "VAL_PATH = \"imageset/val\"\n",
    "\n",
    "# Create empty dictionaries for storing class counts of the datasets\n",
    "TRAIN_CLASS_COUNTS = {}\n",
    "VAL_CLASS_COUNTS = {}\n",
    "\n",
    "# Loop through directories within the training path\n",
    "for folder_name in os.listdir(TRAIN_PATH):\n",
    "    # Retrieve the corresponding class index from mapping using folder name as the key\n",
    "    class_index = imagenet2idx[folder_name][1]\n",
    "    # Count the number of image files within the folder that have a .JPEG extension\n",
    "    image_count = len(glob.glob(os.path.join(TRAIN_PATH, folder_name, \"*.JPEG\")))\n",
    "    # Add the count to the TRAIN_CLASS_COUNTS dictionary\n",
    "    TRAIN_CLASS_COUNTS[class_index] = image_count\n",
    "\n",
    "# Loop through directories within the validation path\n",
    "for folder_name in os.listdir(VAL_PATH):\n",
    "    # Retrieve the corresponding class index from mapping using folder name as the key\n",
    "    class_index = imagenet2idx[folder_name][1]\n",
    "    # Count the number of image files within the folder that have a .JPEG extension\n",
    "    image_count = len(glob.glob(os.path.join(VAL_PATH, folder_name, \"*.JPEG\")))\n",
    "    # Add the count to the VAL_CLASS_COUNTS dictionary\n",
    "    VAL_CLASS_COUNTS[class_index] = image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of images per class in the training dataset\n",
    "print(\"Number of images per class in the training dataset:\")\n",
    "TRAIN_CLASS_COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of images per class in the validation dataset\n",
    "print(\"Number of images per class in the validation dataset:\")\n",
    "VAL_CLASS_COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220478ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# Set the context for plotting\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Create a figure with a size of 9x5 inches\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "\n",
    "# Create the subplot for the training split class counts\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_xlabel('Class Names')\n",
    "ax1.set_ylabel('Class Counts')\n",
    "ax1.set_title('Training Split Class Counts')\n",
    "ax1.bar(range(len(TRAIN_CLASS_COUNTS)), list(TRAIN_CLASS_COUNTS.values()), tick_label=list(TRAIN_CLASS_COUNTS.keys()))\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Create the subplot for the validation split class counts\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_xlabel('Class Names')\n",
    "ax2.set_ylabel('Class Counts')\n",
    "ax2.set_title('Validation Split Class Counts')\n",
    "ax2.bar(range(len(VAL_CLASS_COUNTS)), list(VAL_CLASS_COUNTS.values()), tick_label=list(VAL_CLASS_COUNTS.keys()))\n",
    "ax2.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Adjust the subplot layout for better spacing\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figure to a PNG file\n",
    "plt.savefig('figures/class_count.png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46353a15",
   "metadata": {},
   "source": [
    "### 1.3.2 Class Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aefe93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of training and validation images\n",
    "total_train_images = sum(TRAIN_CLASS_COUNTS.values())\n",
    "total_val_images = sum(VAL_CLASS_COUNTS.values())\n",
    "\n",
    "# Calculate the percentage of each class in the training and validation sets\n",
    "train_percentages = [(count / total_train_images) * 100 for count in TRAIN_CLASS_COUNTS.values()]\n",
    "val_percentages = [(count / total_val_images) * 100 for count in VAL_CLASS_COUNTS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00ef05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the percentage of each class in the training dataset\n",
    "print(\"Training dataset class percentages:\")\n",
    "for class_name, percentage in zip(TRAIN_CLASS_COUNTS.keys(), train_percentages):\n",
    "    print(f\"{class_name}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bf7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage of each class in the validaiton dataset\n",
    "print(\"Validation dataset class percentages:\")\n",
    "for class_name, percentage in zip(VAL_CLASS_COUNTS.keys(), val_percentages):\n",
    "    print(f\"{class_name}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training and validation class percentages into a single DataFrame\n",
    "class_percentages_df = pd.DataFrame({\n",
    "    'Class': list(TRAIN_CLASS_COUNTS.keys()) + list(VAL_CLASS_COUNTS.keys()),\n",
    "    'Percentage': train_percentages + val_percentages,\n",
    "    'Dataset': ['Training'] * len(TRAIN_CLASS_COUNTS) + ['Validation'] * len(VAL_CLASS_COUNTS)\n",
    "})\n",
    "\n",
    "# Set the default seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# Set the context for plotting\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Create a figure with a size of 9x5 inches\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "\n",
    "# Create the subplot for the training and validation dataset class percentages\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "sns.barplot(x='Class', y='Percentage', hue='Dataset', data=class_percentages_df, ax=ax)\n",
    "ax.set_xlabel('Class Names')\n",
    "ax.set_ylabel('Class Percentages')\n",
    "ax.set_title('Class Percentages in Training and Validation Datasets')\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Adjust the subplot layout for better spacing\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figure to a PNG file\n",
    "plt.savefig('figures/class_percentage.png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006807c",
   "metadata": {},
   "source": [
    "### 1.3.3 Image File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through directories within the training path\n",
    "for folder_name in os.listdir(TRAIN_PATH):\n",
    "    # Retrieve the corresponding class index from mapping using folder name as the key\n",
    "    class_index = imagenet2idx[folder_name][1]\n",
    "    # Get a list of the image file paths within the folder that have a .JPEG extension\n",
    "    image_paths = glob.glob(os.path.join(TRAIN_PATH, folder_name, \"*.JPEG\"))\n",
    "    # Analyse the distribution of image file sizes within the folder\n",
    "    image_sizes = [os.path.getsize(path) for path in image_paths]\n",
    "    print(f\"Class {class_index} image size statistics:\")\n",
    "    print(pd.Series(image_sizes).describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
